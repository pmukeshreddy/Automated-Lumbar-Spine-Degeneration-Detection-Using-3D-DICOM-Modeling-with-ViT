{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":71549,"databundleVersionId":8561470,"sourceType":"competition"}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\ntrain_csv = pd.read_csv(\"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train.csv\")\ntrain_csv.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-03T22:37:10.759345Z","iopub.execute_input":"2024-11-03T22:37:10.759636Z","iopub.status.idle":"2024-11-03T22:37:11.799197Z","shell.execute_reply.started":"2024-11-03T22:37:10.759604Z","shell.execute_reply":"2024-11-03T22:37:11.798248Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"   study_id spinal_canal_stenosis_l1_l2 spinal_canal_stenosis_l2_l3  \\\n0   4003253                 Normal/Mild                 Normal/Mild   \n1   4646740                 Normal/Mild                 Normal/Mild   \n2   7143189                 Normal/Mild                 Normal/Mild   \n3   8785691                 Normal/Mild                 Normal/Mild   \n4  10728036                 Normal/Mild                 Normal/Mild   \n\n  spinal_canal_stenosis_l3_l4 spinal_canal_stenosis_l4_l5  \\\n0                 Normal/Mild                 Normal/Mild   \n1                    Moderate                      Severe   \n2                 Normal/Mild                 Normal/Mild   \n3                 Normal/Mild                 Normal/Mild   \n4                 Normal/Mild                 Normal/Mild   \n\n  spinal_canal_stenosis_l5_s1 left_neural_foraminal_narrowing_l1_l2  \\\n0                 Normal/Mild                           Normal/Mild   \n1                 Normal/Mild                           Normal/Mild   \n2                 Normal/Mild                           Normal/Mild   \n3                 Normal/Mild                           Normal/Mild   \n4                 Normal/Mild                           Normal/Mild   \n\n  left_neural_foraminal_narrowing_l2_l3 left_neural_foraminal_narrowing_l3_l4  \\\n0                           Normal/Mild                           Normal/Mild   \n1                           Normal/Mild                           Normal/Mild   \n2                           Normal/Mild                           Normal/Mild   \n3                           Normal/Mild                           Normal/Mild   \n4                           Normal/Mild                           Normal/Mild   \n\n  left_neural_foraminal_narrowing_l4_l5  ... left_subarticular_stenosis_l1_l2  \\\n0                              Moderate  ...                      Normal/Mild   \n1                              Moderate  ...                      Normal/Mild   \n2                           Normal/Mild  ...                      Normal/Mild   \n3                              Moderate  ...                      Normal/Mild   \n4                           Normal/Mild  ...                      Normal/Mild   \n\n  left_subarticular_stenosis_l2_l3 left_subarticular_stenosis_l3_l4  \\\n0                      Normal/Mild                      Normal/Mild   \n1                      Normal/Mild                      Normal/Mild   \n2                      Normal/Mild                      Normal/Mild   \n3                      Normal/Mild                      Normal/Mild   \n4                      Normal/Mild                      Normal/Mild   \n\n  left_subarticular_stenosis_l4_l5 left_subarticular_stenosis_l5_s1  \\\n0                         Moderate                      Normal/Mild   \n1                           Severe                      Normal/Mild   \n2                      Normal/Mild                      Normal/Mild   \n3                      Normal/Mild                      Normal/Mild   \n4                      Normal/Mild                      Normal/Mild   \n\n  right_subarticular_stenosis_l1_l2 right_subarticular_stenosis_l2_l3  \\\n0                       Normal/Mild                       Normal/Mild   \n1                       Normal/Mild                          Moderate   \n2                       Normal/Mild                       Normal/Mild   \n3                       Normal/Mild                       Normal/Mild   \n4                       Normal/Mild                       Normal/Mild   \n\n  right_subarticular_stenosis_l3_l4 right_subarticular_stenosis_l4_l5  \\\n0                       Normal/Mild                       Normal/Mild   \n1                          Moderate                          Moderate   \n2                       Normal/Mild                       Normal/Mild   \n3                       Normal/Mild                       Normal/Mild   \n4                       Normal/Mild                          Moderate   \n\n  right_subarticular_stenosis_l5_s1  \n0                       Normal/Mild  \n1                       Normal/Mild  \n2                       Normal/Mild  \n3                       Normal/Mild  \n4                       Normal/Mild  \n\n[5 rows x 26 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>study_id</th>\n      <th>spinal_canal_stenosis_l1_l2</th>\n      <th>spinal_canal_stenosis_l2_l3</th>\n      <th>spinal_canal_stenosis_l3_l4</th>\n      <th>spinal_canal_stenosis_l4_l5</th>\n      <th>spinal_canal_stenosis_l5_s1</th>\n      <th>left_neural_foraminal_narrowing_l1_l2</th>\n      <th>left_neural_foraminal_narrowing_l2_l3</th>\n      <th>left_neural_foraminal_narrowing_l3_l4</th>\n      <th>left_neural_foraminal_narrowing_l4_l5</th>\n      <th>...</th>\n      <th>left_subarticular_stenosis_l1_l2</th>\n      <th>left_subarticular_stenosis_l2_l3</th>\n      <th>left_subarticular_stenosis_l3_l4</th>\n      <th>left_subarticular_stenosis_l4_l5</th>\n      <th>left_subarticular_stenosis_l5_s1</th>\n      <th>right_subarticular_stenosis_l1_l2</th>\n      <th>right_subarticular_stenosis_l2_l3</th>\n      <th>right_subarticular_stenosis_l3_l4</th>\n      <th>right_subarticular_stenosis_l4_l5</th>\n      <th>right_subarticular_stenosis_l5_s1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4003253</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Moderate</td>\n      <td>...</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Moderate</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4646740</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Moderate</td>\n      <td>Severe</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Moderate</td>\n      <td>...</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Severe</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Moderate</td>\n      <td>Moderate</td>\n      <td>Moderate</td>\n      <td>Normal/Mild</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7143189</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>...</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8785691</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Moderate</td>\n      <td>...</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10728036</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>...</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Normal/Mild</td>\n      <td>Moderate</td>\n      <td>Normal/Mild</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 26 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_series_descriptions = pd.read_csv(\"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_series_descriptions.csv\")\ntrain_series_descriptions.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T22:37:11.801042Z","iopub.execute_input":"2024-11-03T22:37:11.801346Z","iopub.status.idle":"2024-11-03T22:37:11.822341Z","shell.execute_reply.started":"2024-11-03T22:37:11.801308Z","shell.execute_reply":"2024-11-03T22:37:11.821490Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   study_id   series_id series_description\n0   4003253   702807833   Sagittal T2/STIR\n1   4003253  1054713880        Sagittal T1\n2   4003253  2448190387           Axial T2\n3   4646740  3201256954           Axial T2\n4   4646740  3486248476        Sagittal T1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>study_id</th>\n      <th>series_id</th>\n      <th>series_description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4003253</td>\n      <td>702807833</td>\n      <td>Sagittal T2/STIR</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4003253</td>\n      <td>1054713880</td>\n      <td>Sagittal T1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4003253</td>\n      <td>2448190387</td>\n      <td>Axial T2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4646740</td>\n      <td>3201256954</td>\n      <td>Axial T2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4646740</td>\n      <td>3486248476</td>\n      <td>Sagittal T1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_label_coordinates = pd.read_csv(\"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_label_coordinates.csv\")\ntrain_label_coordinates.head(30)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T22:37:11.823523Z","iopub.execute_input":"2024-11-03T22:37:11.823877Z","iopub.status.idle":"2024-11-03T22:37:11.961730Z","shell.execute_reply.started":"2024-11-03T22:37:11.823835Z","shell.execute_reply":"2024-11-03T22:37:11.960855Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"    study_id   series_id  instance_number                         condition  \\\n0    4003253   702807833                8             Spinal Canal Stenosis   \n1    4003253   702807833                8             Spinal Canal Stenosis   \n2    4003253   702807833                8             Spinal Canal Stenosis   \n3    4003253   702807833                8             Spinal Canal Stenosis   \n4    4003253   702807833                8             Spinal Canal Stenosis   \n5    4003253  1054713880                4  Right Neural Foraminal Narrowing   \n6    4003253  1054713880                4  Right Neural Foraminal Narrowing   \n7    4003253  1054713880                5  Right Neural Foraminal Narrowing   \n8    4003253  1054713880                6  Right Neural Foraminal Narrowing   \n9    4003253  1054713880                6  Right Neural Foraminal Narrowing   \n10   4003253  1054713880               11   Left Neural Foraminal Narrowing   \n11   4003253  1054713880               11   Left Neural Foraminal Narrowing   \n12   4003253  1054713880               11   Left Neural Foraminal Narrowing   \n13   4003253  1054713880               12   Left Neural Foraminal Narrowing   \n14   4003253  1054713880               12   Left Neural Foraminal Narrowing   \n15   4003253  2448190387                3        Left Subarticular Stenosis   \n16   4003253  2448190387                4       Right Subarticular Stenosis   \n17   4003253  2448190387               11        Left Subarticular Stenosis   \n18   4003253  2448190387               11       Right Subarticular Stenosis   \n19   4003253  2448190387               19        Left Subarticular Stenosis   \n20   4003253  2448190387               19       Right Subarticular Stenosis   \n21   4003253  2448190387               28        Left Subarticular Stenosis   \n22   4003253  2448190387               28       Right Subarticular Stenosis   \n23   4003253  2448190387               35        Left Subarticular Stenosis   \n24   4003253  2448190387               35       Right Subarticular Stenosis   \n25   4646740  3201256954               15       Right Subarticular Stenosis   \n26   4646740  3201256954               16        Left Subarticular Stenosis   \n27   4646740  3201256954               22        Left Subarticular Stenosis   \n28   4646740  3201256954               22       Right Subarticular Stenosis   \n29   4646740  3201256954               28       Right Subarticular Stenosis   \n\n    level           x           y  \n0   L1/L2  322.831858  227.964602  \n1   L2/L3  320.571429  295.714286  \n2   L3/L4  323.030303  371.818182  \n3   L4/L5  335.292035  427.327434  \n4   L5/S1  353.415929  483.964602  \n5   L4/L5  187.961759  251.839388  \n6   L5/S1  198.240918  285.613767  \n7   L3/L4  187.227533  210.722753  \n8   L1/L2  194.569790  127.755258  \n9   L2/L3  191.632887  165.934990  \n10  L1/L2  196.070671  126.021201  \n11  L4/L5  186.504472  251.592129  \n12  L5/S1  197.100569  289.457306  \n13  L2/L3  191.321555  170.120141  \n14  L3/L4  187.878354  217.245081  \n15  L1/L2  179.126448  161.235521  \n16  L1/L2  145.288771  158.624642  \n17  L2/L3  180.979730  158.764479  \n18  L2/L3  145.900042  157.096466  \n19  L3/L4  176.037645  157.528958  \n20  L3/L4  142.843690  156.179561  \n21  L4/L5  172.948842  156.911197  \n22  L4/L5  147.428218  158.013372  \n23  L5/S1  179.744208  161.853282  \n24  L5/S1  145.900042  161.375358  \n25  L1/L2  184.180995  263.239819  \n26  L1/L2  235.317073  264.083624  \n27  L2/L3  235.317073  254.717770  \n28  L2/L3  200.977376  256.868778  \n29  L3/L4  204.452489  252.814480  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>study_id</th>\n      <th>series_id</th>\n      <th>instance_number</th>\n      <th>condition</th>\n      <th>level</th>\n      <th>x</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4003253</td>\n      <td>702807833</td>\n      <td>8</td>\n      <td>Spinal Canal Stenosis</td>\n      <td>L1/L2</td>\n      <td>322.831858</td>\n      <td>227.964602</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4003253</td>\n      <td>702807833</td>\n      <td>8</td>\n      <td>Spinal Canal Stenosis</td>\n      <td>L2/L3</td>\n      <td>320.571429</td>\n      <td>295.714286</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4003253</td>\n      <td>702807833</td>\n      <td>8</td>\n      <td>Spinal Canal Stenosis</td>\n      <td>L3/L4</td>\n      <td>323.030303</td>\n      <td>371.818182</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4003253</td>\n      <td>702807833</td>\n      <td>8</td>\n      <td>Spinal Canal Stenosis</td>\n      <td>L4/L5</td>\n      <td>335.292035</td>\n      <td>427.327434</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4003253</td>\n      <td>702807833</td>\n      <td>8</td>\n      <td>Spinal Canal Stenosis</td>\n      <td>L5/S1</td>\n      <td>353.415929</td>\n      <td>483.964602</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>4003253</td>\n      <td>1054713880</td>\n      <td>4</td>\n      <td>Right Neural Foraminal Narrowing</td>\n      <td>L4/L5</td>\n      <td>187.961759</td>\n      <td>251.839388</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>4003253</td>\n      <td>1054713880</td>\n      <td>4</td>\n      <td>Right Neural Foraminal Narrowing</td>\n      <td>L5/S1</td>\n      <td>198.240918</td>\n      <td>285.613767</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>4003253</td>\n      <td>1054713880</td>\n      <td>5</td>\n      <td>Right Neural Foraminal Narrowing</td>\n      <td>L3/L4</td>\n      <td>187.227533</td>\n      <td>210.722753</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>4003253</td>\n      <td>1054713880</td>\n      <td>6</td>\n      <td>Right Neural Foraminal Narrowing</td>\n      <td>L1/L2</td>\n      <td>194.569790</td>\n      <td>127.755258</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>4003253</td>\n      <td>1054713880</td>\n      <td>6</td>\n      <td>Right Neural Foraminal Narrowing</td>\n      <td>L2/L3</td>\n      <td>191.632887</td>\n      <td>165.934990</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>4003253</td>\n      <td>1054713880</td>\n      <td>11</td>\n      <td>Left Neural Foraminal Narrowing</td>\n      <td>L1/L2</td>\n      <td>196.070671</td>\n      <td>126.021201</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>4003253</td>\n      <td>1054713880</td>\n      <td>11</td>\n      <td>Left Neural Foraminal Narrowing</td>\n      <td>L4/L5</td>\n      <td>186.504472</td>\n      <td>251.592129</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>4003253</td>\n      <td>1054713880</td>\n      <td>11</td>\n      <td>Left Neural Foraminal Narrowing</td>\n      <td>L5/S1</td>\n      <td>197.100569</td>\n      <td>289.457306</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>4003253</td>\n      <td>1054713880</td>\n      <td>12</td>\n      <td>Left Neural Foraminal Narrowing</td>\n      <td>L2/L3</td>\n      <td>191.321555</td>\n      <td>170.120141</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>4003253</td>\n      <td>1054713880</td>\n      <td>12</td>\n      <td>Left Neural Foraminal Narrowing</td>\n      <td>L3/L4</td>\n      <td>187.878354</td>\n      <td>217.245081</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>4003253</td>\n      <td>2448190387</td>\n      <td>3</td>\n      <td>Left Subarticular Stenosis</td>\n      <td>L1/L2</td>\n      <td>179.126448</td>\n      <td>161.235521</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>4003253</td>\n      <td>2448190387</td>\n      <td>4</td>\n      <td>Right Subarticular Stenosis</td>\n      <td>L1/L2</td>\n      <td>145.288771</td>\n      <td>158.624642</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>4003253</td>\n      <td>2448190387</td>\n      <td>11</td>\n      <td>Left Subarticular Stenosis</td>\n      <td>L2/L3</td>\n      <td>180.979730</td>\n      <td>158.764479</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>4003253</td>\n      <td>2448190387</td>\n      <td>11</td>\n      <td>Right Subarticular Stenosis</td>\n      <td>L2/L3</td>\n      <td>145.900042</td>\n      <td>157.096466</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>4003253</td>\n      <td>2448190387</td>\n      <td>19</td>\n      <td>Left Subarticular Stenosis</td>\n      <td>L3/L4</td>\n      <td>176.037645</td>\n      <td>157.528958</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>4003253</td>\n      <td>2448190387</td>\n      <td>19</td>\n      <td>Right Subarticular Stenosis</td>\n      <td>L3/L4</td>\n      <td>142.843690</td>\n      <td>156.179561</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>4003253</td>\n      <td>2448190387</td>\n      <td>28</td>\n      <td>Left Subarticular Stenosis</td>\n      <td>L4/L5</td>\n      <td>172.948842</td>\n      <td>156.911197</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>4003253</td>\n      <td>2448190387</td>\n      <td>28</td>\n      <td>Right Subarticular Stenosis</td>\n      <td>L4/L5</td>\n      <td>147.428218</td>\n      <td>158.013372</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>4003253</td>\n      <td>2448190387</td>\n      <td>35</td>\n      <td>Left Subarticular Stenosis</td>\n      <td>L5/S1</td>\n      <td>179.744208</td>\n      <td>161.853282</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>4003253</td>\n      <td>2448190387</td>\n      <td>35</td>\n      <td>Right Subarticular Stenosis</td>\n      <td>L5/S1</td>\n      <td>145.900042</td>\n      <td>161.375358</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>4646740</td>\n      <td>3201256954</td>\n      <td>15</td>\n      <td>Right Subarticular Stenosis</td>\n      <td>L1/L2</td>\n      <td>184.180995</td>\n      <td>263.239819</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>4646740</td>\n      <td>3201256954</td>\n      <td>16</td>\n      <td>Left Subarticular Stenosis</td>\n      <td>L1/L2</td>\n      <td>235.317073</td>\n      <td>264.083624</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>4646740</td>\n      <td>3201256954</td>\n      <td>22</td>\n      <td>Left Subarticular Stenosis</td>\n      <td>L2/L3</td>\n      <td>235.317073</td>\n      <td>254.717770</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>4646740</td>\n      <td>3201256954</td>\n      <td>22</td>\n      <td>Right Subarticular Stenosis</td>\n      <td>L2/L3</td>\n      <td>200.977376</td>\n      <td>256.868778</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>4646740</td>\n      <td>3201256954</td>\n      <td>28</td>\n      <td>Right Subarticular Stenosis</td>\n      <td>L3/L4</td>\n      <td>204.452489</td>\n      <td>252.814480</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"\n\nfiltered_data = train_label_coordinates[train_label_coordinates['series_id'] == 1252873726]\n\n# Print the filtered data\nprint(len(filtered_data))\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-03T22:37:11.963494Z","iopub.execute_input":"2024-11-03T22:37:11.963867Z","iopub.status.idle":"2024-11-03T22:37:11.970196Z","shell.execute_reply.started":"2024-11-03T22:37:11.963823Z","shell.execute_reply":"2024-11-03T22:37:11.969267Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"10\n","output_type":"stream"}]},{"cell_type":"code","source":"train_label_coordinates[\"condition\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-11-03T22:37:11.973262Z","iopub.execute_input":"2024-11-03T22:37:11.973552Z","iopub.status.idle":"2024-11-03T22:37:11.994162Z","shell.execute_reply.started":"2024-11-03T22:37:11.973521Z","shell.execute_reply":"2024-11-03T22:37:11.992955Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"condition\nLeft Neural Foraminal Narrowing     9860\nRight Neural Foraminal Narrowing    9859\nSpinal Canal Stenosis               9753\nRight Subarticular Stenosis         9612\nLeft Subarticular Stenosis          9608\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"train_series_descriptions[\"series_description\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-11-03T22:37:11.995328Z","iopub.execute_input":"2024-11-03T22:37:11.995617Z","iopub.status.idle":"2024-11-03T22:37:12.003783Z","shell.execute_reply.started":"2024-11-03T22:37:11.995580Z","shell.execute_reply":"2024-11-03T22:37:12.002881Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"series_description\nAxial T2            2340\nSagittal T1         1980\nSagittal T2/STIR    1974\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"condition = {\"Sagittal T2/STIR\":[\"Spinal Canal Stenosis\"],\"Axial T2\":[\"Left Subarticular Stenosis\",\"Right Subarticular Stenosis\"],\n            \"Sagittal T2/STIR\":[\"Left Neural Foraminal Narrowing\",\"Right Neural Foraminal Narrowing\"]}","metadata":{"execution":{"iopub.status.busy":"2024-11-03T22:37:12.005197Z","iopub.execute_input":"2024-11-03T22:37:12.005510Z","iopub.status.idle":"2024-11-03T22:37:12.010700Z","shell.execute_reply.started":"2024-11-03T22:37:12.005479Z","shell.execute_reply":"2024-11-03T22:37:12.009834Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"label_map = {\"nomal_mild\":0,\"moderate\":1,\"severe\":2}","metadata":{"execution":{"iopub.status.busy":"2024-11-03T22:37:12.011714Z","iopub.execute_input":"2024-11-03T22:37:12.012023Z","iopub.status.idle":"2024-11-03T22:37:12.019840Z","shell.execute_reply.started":"2024-11-03T22:37:12.011981Z","shell.execute_reply":"2024-11-03T22:37:12.018982Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def reshape_row(row):\n        data = {\"study_id\":[],\"condition\":[],\"level\":[],\"severity\":[]}\n        for coloum , value in row.items():\n            if coloum not in [\"study_id\",\"series_id\",\"instance_number\",\"x\",\"y\",\"series_description\"]:\n                parts = coloum.split(\"_\")\n                condition = \" \".join([word.capitalize() for word in parts[:-2]])\n                level = parts[-2].capitalize() + \"/\" + parts[-1].capitalize()\n                data[\"study_id\"].append(row[\"study_id\"])\n                data[\"condition\"].append(condition)\n                data[\"level\"].append(level)\n                data[\"severity\"].append(value)\n        return pd.DataFrame(data)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T22:37:12.020775Z","iopub.execute_input":"2024-11-03T22:37:12.021071Z","iopub.status.idle":"2024-11-03T22:37:12.028742Z","shell.execute_reply.started":"2024-11-03T22:37:12.021025Z","shell.execute_reply":"2024-11-03T22:37:12.027772Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def retrive_coordinate_training_data():\n    new_train_df = pd.concat([reshape_row(row) for _,row in train_csv.iterrows()])\n    mergred_df = pd.merge(new_train_df,train_label_coordinates,on=[\"study_id\",\"condition\",\"level\"],how=\"inner\")\n    final_mergred_df = pd.merge(mergred_df,train_series_descriptions,on=[\"study_id\",\"series_id\"],how=\"inner\")\n    final_mergred_df[\"severity\"] = final_mergred_df[\"severity\"].map({\"Normal/Mild\":\"normal_mild\",\"Moderate\":\"moderate\",\"Severe\":\"severe\"})\n    final_mergred_df[\"row_id\"] = (final_mergred_df[\"study_id\"].astype(str)+\"_\"+final_mergred_df[\"condition\"].str.lower().str.replace(\" \",\"_\")\n                                 +\"_\"+final_mergred_df[\"level\"].str.lower().str.replace(\"/\",\"_\"))\n    final_mergred_df[\"image_path\"] = (\"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_images\"\n                                     +final_mergred_df[\"study_id\"].astype(str)+\"/\"+final_mergred_df[\"series_id\"].astype(str)+\"/\"+final_mergred_df[\"instance_number\"].astype(str)+\".dcm\" )\n    return final_mergred_df","metadata":{"execution":{"iopub.status.busy":"2024-11-03T22:37:12.029822Z","iopub.execute_input":"2024-11-03T22:37:12.030380Z","iopub.status.idle":"2024-11-03T22:37:12.039624Z","shell.execute_reply.started":"2024-11-03T22:37:12.030338Z","shell.execute_reply":"2024-11-03T22:37:12.038627Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_data = retrive_coordinate_training_data()","metadata":{"execution":{"iopub.status.busy":"2024-11-03T22:37:12.040717Z","iopub.execute_input":"2024-11-03T22:37:12.041678Z","iopub.status.idle":"2024-11-03T22:37:13.768187Z","shell.execute_reply.started":"2024-11-03T22:37:12.041646Z","shell.execute_reply":"2024-11-03T22:37:13.767145Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2024-11-03T02:38:35.132287Z","iopub.execute_input":"2024-11-03T02:38:35.132617Z","iopub.status.idle":"2024-11-03T02:38:35.149949Z","shell.execute_reply.started":"2024-11-03T02:38:35.132583Z","shell.execute_reply":"2024-11-03T02:38:35.148959Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"         study_id                    condition  level     severity  \\\n0         4003253        Spinal Canal Stenosis  L1/L2  normal_mild   \n1         4003253        Spinal Canal Stenosis  L2/L3  normal_mild   \n2         4003253        Spinal Canal Stenosis  L3/L4  normal_mild   \n3         4003253        Spinal Canal Stenosis  L4/L5  normal_mild   \n4         4003253        Spinal Canal Stenosis  L5/S1  normal_mild   \n...           ...                          ...    ...          ...   \n48687  4290709089  Right Subarticular Stenosis  L1/L2  normal_mild   \n48688  4290709089  Right Subarticular Stenosis  L2/L3  normal_mild   \n48689  4290709089  Right Subarticular Stenosis  L3/L4  normal_mild   \n48690  4290709089  Right Subarticular Stenosis  L4/L5  normal_mild   \n48691  4290709089  Right Subarticular Stenosis  L5/S1  normal_mild   \n\n        series_id  instance_number           x           y series_description  \\\n0       702807833                8  322.831858  227.964602   Sagittal T2/STIR   \n1       702807833                8  320.571429  295.714286   Sagittal T2/STIR   \n2       702807833                8  323.030303  371.818182   Sagittal T2/STIR   \n3       702807833                8  335.292035  427.327434   Sagittal T2/STIR   \n4       702807833                8  353.415929  483.964602   Sagittal T2/STIR   \n...           ...              ...         ...         ...                ...   \n48687  3390218084                2  307.180844  354.869960           Axial T2   \n48688  3390218084                6  301.440933  362.044847           Axial T2   \n48689  3390218084               10  302.875911  356.304937           Axial T2   \n48690  3390218084               15  305.745866  340.520184           Axial T2   \n48691  3390218084               21  302.875911  364.627811           Axial T2   \n\n                                             row_id  \\\n0               4003253_spinal_canal_stenosis_l1_l2   \n1               4003253_spinal_canal_stenosis_l2_l3   \n2               4003253_spinal_canal_stenosis_l3_l4   \n3               4003253_spinal_canal_stenosis_l4_l5   \n4               4003253_spinal_canal_stenosis_l5_s1   \n...                                             ...   \n48687  4290709089_right_subarticular_stenosis_l1_l2   \n48688  4290709089_right_subarticular_stenosis_l2_l3   \n48689  4290709089_right_subarticular_stenosis_l3_l4   \n48690  4290709089_right_subarticular_stenosis_l4_l5   \n48691  4290709089_right_subarticular_stenosis_l5_s1   \n\n                                              image_path  \n0      /kaggle/input/rsna-2024-lumbar-spine-degenerat...  \n1      /kaggle/input/rsna-2024-lumbar-spine-degenerat...  \n2      /kaggle/input/rsna-2024-lumbar-spine-degenerat...  \n3      /kaggle/input/rsna-2024-lumbar-spine-degenerat...  \n4      /kaggle/input/rsna-2024-lumbar-spine-degenerat...  \n...                                                  ...  \n48687  /kaggle/input/rsna-2024-lumbar-spine-degenerat...  \n48688  /kaggle/input/rsna-2024-lumbar-spine-degenerat...  \n48689  /kaggle/input/rsna-2024-lumbar-spine-degenerat...  \n48690  /kaggle/input/rsna-2024-lumbar-spine-degenerat...  \n48691  /kaggle/input/rsna-2024-lumbar-spine-degenerat...  \n\n[48692 rows x 11 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>study_id</th>\n      <th>condition</th>\n      <th>level</th>\n      <th>severity</th>\n      <th>series_id</th>\n      <th>instance_number</th>\n      <th>x</th>\n      <th>y</th>\n      <th>series_description</th>\n      <th>row_id</th>\n      <th>image_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4003253</td>\n      <td>Spinal Canal Stenosis</td>\n      <td>L1/L2</td>\n      <td>normal_mild</td>\n      <td>702807833</td>\n      <td>8</td>\n      <td>322.831858</td>\n      <td>227.964602</td>\n      <td>Sagittal T2/STIR</td>\n      <td>4003253_spinal_canal_stenosis_l1_l2</td>\n      <td>/kaggle/input/rsna-2024-lumbar-spine-degenerat...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4003253</td>\n      <td>Spinal Canal Stenosis</td>\n      <td>L2/L3</td>\n      <td>normal_mild</td>\n      <td>702807833</td>\n      <td>8</td>\n      <td>320.571429</td>\n      <td>295.714286</td>\n      <td>Sagittal T2/STIR</td>\n      <td>4003253_spinal_canal_stenosis_l2_l3</td>\n      <td>/kaggle/input/rsna-2024-lumbar-spine-degenerat...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4003253</td>\n      <td>Spinal Canal Stenosis</td>\n      <td>L3/L4</td>\n      <td>normal_mild</td>\n      <td>702807833</td>\n      <td>8</td>\n      <td>323.030303</td>\n      <td>371.818182</td>\n      <td>Sagittal T2/STIR</td>\n      <td>4003253_spinal_canal_stenosis_l3_l4</td>\n      <td>/kaggle/input/rsna-2024-lumbar-spine-degenerat...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4003253</td>\n      <td>Spinal Canal Stenosis</td>\n      <td>L4/L5</td>\n      <td>normal_mild</td>\n      <td>702807833</td>\n      <td>8</td>\n      <td>335.292035</td>\n      <td>427.327434</td>\n      <td>Sagittal T2/STIR</td>\n      <td>4003253_spinal_canal_stenosis_l4_l5</td>\n      <td>/kaggle/input/rsna-2024-lumbar-spine-degenerat...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4003253</td>\n      <td>Spinal Canal Stenosis</td>\n      <td>L5/S1</td>\n      <td>normal_mild</td>\n      <td>702807833</td>\n      <td>8</td>\n      <td>353.415929</td>\n      <td>483.964602</td>\n      <td>Sagittal T2/STIR</td>\n      <td>4003253_spinal_canal_stenosis_l5_s1</td>\n      <td>/kaggle/input/rsna-2024-lumbar-spine-degenerat...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>48687</th>\n      <td>4290709089</td>\n      <td>Right Subarticular Stenosis</td>\n      <td>L1/L2</td>\n      <td>normal_mild</td>\n      <td>3390218084</td>\n      <td>2</td>\n      <td>307.180844</td>\n      <td>354.869960</td>\n      <td>Axial T2</td>\n      <td>4290709089_right_subarticular_stenosis_l1_l2</td>\n      <td>/kaggle/input/rsna-2024-lumbar-spine-degenerat...</td>\n    </tr>\n    <tr>\n      <th>48688</th>\n      <td>4290709089</td>\n      <td>Right Subarticular Stenosis</td>\n      <td>L2/L3</td>\n      <td>normal_mild</td>\n      <td>3390218084</td>\n      <td>6</td>\n      <td>301.440933</td>\n      <td>362.044847</td>\n      <td>Axial T2</td>\n      <td>4290709089_right_subarticular_stenosis_l2_l3</td>\n      <td>/kaggle/input/rsna-2024-lumbar-spine-degenerat...</td>\n    </tr>\n    <tr>\n      <th>48689</th>\n      <td>4290709089</td>\n      <td>Right Subarticular Stenosis</td>\n      <td>L3/L4</td>\n      <td>normal_mild</td>\n      <td>3390218084</td>\n      <td>10</td>\n      <td>302.875911</td>\n      <td>356.304937</td>\n      <td>Axial T2</td>\n      <td>4290709089_right_subarticular_stenosis_l3_l4</td>\n      <td>/kaggle/input/rsna-2024-lumbar-spine-degenerat...</td>\n    </tr>\n    <tr>\n      <th>48690</th>\n      <td>4290709089</td>\n      <td>Right Subarticular Stenosis</td>\n      <td>L4/L5</td>\n      <td>normal_mild</td>\n      <td>3390218084</td>\n      <td>15</td>\n      <td>305.745866</td>\n      <td>340.520184</td>\n      <td>Axial T2</td>\n      <td>4290709089_right_subarticular_stenosis_l4_l5</td>\n      <td>/kaggle/input/rsna-2024-lumbar-spine-degenerat...</td>\n    </tr>\n    <tr>\n      <th>48691</th>\n      <td>4290709089</td>\n      <td>Right Subarticular Stenosis</td>\n      <td>L5/S1</td>\n      <td>normal_mild</td>\n      <td>3390218084</td>\n      <td>21</td>\n      <td>302.875911</td>\n      <td>364.627811</td>\n      <td>Axial T2</td>\n      <td>4290709089_right_subarticular_stenosis_l5_s1</td>\n      <td>/kaggle/input/rsna-2024-lumbar-spine-degenerat...</td>\n    </tr>\n  </tbody>\n</table>\n<p>48692 rows × 11 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_data[\"severity\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-11-03T22:58:22.563910Z","iopub.execute_input":"2024-11-03T22:58:22.564765Z","iopub.status.idle":"2024-11-03T22:58:22.578315Z","shell.execute_reply.started":"2024-11-03T22:58:22.564725Z","shell.execute_reply":"2024-11-03T22:58:22.577359Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"severity\nnormal_mild    37626\nmoderate        7950\nsevere          3081\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_images/1002894806/1252873726","metadata":{}},{"cell_type":"code","source":"filtered_data = train_data[train_data['series_id'] == 1252873726]\n\n# Print the filtered data\nprint(len(filtered_data))\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-03T22:58:24.086630Z","iopub.execute_input":"2024-11-03T22:58:24.087487Z","iopub.status.idle":"2024-11-03T22:58:24.094454Z","shell.execute_reply.started":"2024-11-03T22:58:24.087432Z","shell.execute_reply":"2024-11-03T22:58:24.093427Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"10\n","output_type":"stream"}]},{"cell_type":"markdown","source":"converting dicom images to point cloud data","metadata":{}},{"cell_type":"markdown","source":"# DICOM to Point Cloud Conversion Summary Table\n\n| Step | Component | Description | Key Functions/Libraries |\n|------|-----------|-------------|-------------------------|\n| 1 | DICOM Reading | Load DICOM files and extract metadata | `pydicom.dcmread()` |\n| 2 | Image Processing | Resize and prepare image data | `cv2.resize()`, `torch.nn.functional.adaptive_max_pool2d()` |\n| 3 | Point Cloud Creation | Convert image data to 3D points | `numpy.where()`, `o3d.geometry.PointCloud()` |\n| 4 | Color Assignment | Assign colors to points based on image intensity | `numpy.pad()` |\n| 5 | Transformation | Create and apply transformation matrices | `numpy.matrix()` |\n| 6 | Slice Stacking | Stack multiple slices based on thickness | Custom loop |\n| 7 | Downsampling | Reduce point cloud density for large datasets | Slicing with step: `[::downsampling_factor_iter]` |\n| 8 | Series Handling | Process different types of series (T1, T2, etc.) | Conditional padding |\n| 9 | Point Cloud Combination | Combine all processed slices into one point cloud | `+=` operator on `o3d.geometry.PointCloud` |\n\nKey Parameters:\n- `dir_path`: Directory containing DICOM files\n- `series_type_dict`: Dictionary mapping series IDs to descriptions\n- `resize_slice`: Boolean to control slice resizing\n- `img_size`: Target size for resized images\n- `downsampling_factor`: Factor to reduce point cloud density\n- `resize_slices`: Boolean to control 3D slice resizing\n- `stack_slices_thickness`: Boolean to control slice stacking\n\nMain Libraries:\n- `open3d`: For point cloud operations\n- `pydicom`: For reading DICOM files\n- `numpy`: For numerical operations\n- `torch`: For advanced image processing (optional)\n- `cv2`: For basic image processing\n\nOutput:\n- A single `o3d.geometry.PointCloud` object representing all processed DICOM data","metadata":{}},{"cell_type":"code","source":"pip install open3d","metadata":{"execution":{"iopub.status.busy":"2024-11-03T22:58:28.859450Z","iopub.execute_input":"2024-11-03T22:58:28.859828Z","iopub.status.idle":"2024-11-03T22:58:57.711698Z","shell.execute_reply.started":"2024-11-03T22:58:28.859790Z","shell.execute_reply":"2024-11-03T22:58:57.710557Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"Collecting open3d\n  Downloading open3d-0.18.0-cp310-cp310-manylinux_2_27_x86_64.whl.metadata (4.2 kB)\nRequirement already satisfied: numpy>=1.18.0 in /opt/conda/lib/python3.10/site-packages (from open3d) (1.26.4)\nCollecting dash>=2.6.0 (from open3d)\n  Downloading dash-2.18.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: werkzeug>=2.2.3 in /opt/conda/lib/python3.10/site-packages (from open3d) (3.0.4)\nRequirement already satisfied: nbformat>=5.7.0 in /opt/conda/lib/python3.10/site-packages (from open3d) (5.10.4)\nCollecting configargparse (from open3d)\n  Downloading ConfigArgParse-1.7-py3-none-any.whl.metadata (23 kB)\nCollecting ipywidgets>=8.0.4 (from open3d)\n  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\nCollecting addict (from open3d)\n  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\nRequirement already satisfied: pillow>=9.3.0 in /opt/conda/lib/python3.10/site-packages (from open3d) (10.3.0)\nRequirement already satisfied: matplotlib>=3 in /opt/conda/lib/python3.10/site-packages (from open3d) (3.7.5)\nRequirement already satisfied: pandas>=1.0 in /opt/conda/lib/python3.10/site-packages (from open3d) (2.2.2)\nRequirement already satisfied: pyyaml>=5.4.1 in /opt/conda/lib/python3.10/site-packages (from open3d) (6.0.2)\nRequirement already satisfied: scikit-learn>=0.21 in /opt/conda/lib/python3.10/site-packages (from open3d) (1.2.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from open3d) (4.66.4)\nCollecting pyquaternion (from open3d)\n  Downloading pyquaternion-0.9.9-py3-none-any.whl.metadata (1.4 kB)\nRequirement already satisfied: Flask<3.1,>=1.0.4 in /opt/conda/lib/python3.10/site-packages (from dash>=2.6.0->open3d) (3.0.3)\nRequirement already satisfied: plotly>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from dash>=2.6.0->open3d) (5.22.0)\nCollecting dash-html-components==2.0.0 (from dash>=2.6.0->open3d)\n  Downloading dash_html_components-2.0.0-py3-none-any.whl.metadata (3.8 kB)\nCollecting dash-core-components==2.0.0 (from dash>=2.6.0->open3d)\n  Downloading dash_core_components-2.0.0-py3-none-any.whl.metadata (2.9 kB)\nCollecting dash-table==5.0.0 (from dash>=2.6.0->open3d)\n  Downloading dash_table-5.0.0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.10/site-packages (from dash>=2.6.0->open3d) (7.0.0)\nRequirement already satisfied: typing-extensions>=4.1.1 in /opt/conda/lib/python3.10/site-packages (from dash>=2.6.0->open3d) (4.12.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from dash>=2.6.0->open3d) (2.32.3)\nRequirement already satisfied: retrying in /opt/conda/lib/python3.10/site-packages (from dash>=2.6.0->open3d) (1.3.3)\nRequirement already satisfied: nest-asyncio in /opt/conda/lib/python3.10/site-packages (from dash>=2.6.0->open3d) (1.6.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from dash>=2.6.0->open3d) (70.0.0)\nRequirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from ipywidgets>=8.0.4->open3d) (0.2.2)\nRequirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets>=8.0.4->open3d) (8.21.0)\nRequirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets>=8.0.4->open3d) (5.14.3)\nCollecting widgetsnbextension~=4.0.12 (from ipywidgets>=8.0.4->open3d)\n  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\nCollecting jupyterlab-widgets~=3.0.12 (from ipywidgets>=8.0.4->open3d)\n  Downloading jupyterlab_widgets-3.0.13-py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3->open3d) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3->open3d) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3->open3d) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3->open3d) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3->open3d) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3->open3d) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3->open3d) (2.9.0.post0)\nRequirement already satisfied: fastjsonschema>=2.15 in /opt/conda/lib/python3.10/site-packages (from nbformat>=5.7.0->open3d) (2.19.1)\nRequirement already satisfied: jsonschema>=2.6 in /opt/conda/lib/python3.10/site-packages (from nbformat>=5.7.0->open3d) (4.22.0)\nRequirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.10/site-packages (from nbformat>=5.7.0->open3d) (5.7.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0->open3d) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0->open3d) (2024.1)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21->open3d) (1.14.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21->open3d) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21->open3d) (3.5.0)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=2.2.3->open3d) (2.1.5)\nRequirement already satisfied: Jinja2>=3.1.2 in /opt/conda/lib/python3.10/site-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (3.1.4)\nRequirement already satisfied: itsdangerous>=2.1.2 in /opt/conda/lib/python3.10/site-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (2.2.0)\nRequirement already satisfied: click>=8.1.3 in /opt/conda/lib/python3.10/site-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (8.1.7)\nRequirement already satisfied: blinker>=1.6.2 in /opt/conda/lib/python3.10/site-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (1.8.2)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (5.1.1)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.19.1)\nRequirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.1.7)\nRequirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.47)\nRequirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.18.0)\nRequirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.6.2)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (1.2.0)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.9.0)\nRequirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (23.2.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.35.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.18.1)\nRequirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.7.0->open3d) (3.11.0)\nRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (8.3.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3->open3d) (1.16.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata->dash>=2.6.0->open3d) (3.19.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->dash>=2.6.0->open3d) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->dash>=2.6.0->open3d) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->dash>=2.6.0->open3d) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->dash>=2.6.0->open3d) (2024.8.30)\nRequirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.4)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.13)\nRequirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.0.1)\nRequirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.4.1)\nRequirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.2)\nDownloading open3d-0.18.0-cp310-cp310-manylinux_2_27_x86_64.whl (399.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.7/399.7 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading dash-2.18.1-py3-none-any.whl (7.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\nDownloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\nDownloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\nDownloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\nDownloading ConfigArgParse-1.7-py3-none-any.whl (25 kB)\nDownloading pyquaternion-0.9.9-py3-none-any.whl (14 kB)\nDownloading jupyterlab_widgets-3.0.13-py3-none-any.whl (214 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.4/214.4 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: dash-table, dash-html-components, dash-core-components, addict, widgetsnbextension, pyquaternion, jupyterlab-widgets, configargparse, dash, ipywidgets, open3d\n  Attempting uninstall: widgetsnbextension\n    Found existing installation: widgetsnbextension 3.6.9\n    Uninstalling widgetsnbextension-3.6.9:\n      Successfully uninstalled widgetsnbextension-3.6.9\n  Attempting uninstall: jupyterlab-widgets\n    Found existing installation: jupyterlab_widgets 3.0.11\n    Uninstalling jupyterlab_widgets-3.0.11:\n      Successfully uninstalled jupyterlab_widgets-3.0.11\n  Attempting uninstall: ipywidgets\n    Found existing installation: ipywidgets 7.7.1\n    Uninstalling ipywidgets-7.7.1:\n      Successfully uninstalled ipywidgets-7.7.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 0.22.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.10.0, but you have google-cloud-bigquery 2.34.4 which is incompatible.\nbigframes 0.22.0 requires google-cloud-storage>=2.0.0, but you have google-cloud-storage 1.44.0 which is incompatible.\nbigframes 0.22.0 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.2.2 which is incompatible.\ndataproc-jupyter-plugin 0.1.79 requires pydantic~=1.10.0, but you have pydantic 2.9.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed addict-2.4.0 configargparse-1.7 dash-2.18.1 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 ipywidgets-8.1.5 jupyterlab-widgets-3.0.13 open3d-0.18.0 pyquaternion-0.9.9 widgetsnbextension-4.0.13\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"def dicom_to_pcd(directory_path, series_type_dict=None, resize_slice=True, img_size=(256, 256), downsampling_factor=1, stack_slices_thickness=True, series_dsc=None):\n    pcd_overall = o3d.geometry.PointCloud()\n    dicom_files = glob.glob(os.path.join(directory_path, \"**/*.dcm\"), recursive=True)\n    \n    if not dicom_files:\n        print(f\"No DICOM files found in {directory_path}\")\n        return None\n    \n    print(f\"Found {len(dicom_files)} DICOM files in {directory_path}\")\n    \n    for path in dicom_files:\n        try:\n            dicom_slices = dcmread(path)\n            series_id = os.path.basename(os.path.dirname(path))\n            # Assuming you have processing logic here, add debug prints:\n            print(f\"Processing DICOM file: {path}\")\n            # Add your DICOM to point cloud processing here\n        except Exception as e:\n            print(f\"Error processing {path}: {e}\")\n            continue\n    \n    # Ensure pcd_overall is not empty\n    if not pcd_overall.points:\n        print(f\"No point cloud data generated from {directory_path}. Check if the processing logic is correct.\")\n        return None\n    \n    return pcd_overall\n","metadata":{"execution":{"iopub.status.busy":"2024-11-03T22:58:57.715593Z","iopub.execute_input":"2024-11-03T22:58:57.715925Z","iopub.status.idle":"2024-11-03T22:58:57.724938Z","shell.execute_reply.started":"2024-11-03T22:58:57.715887Z","shell.execute_reply":"2024-11-03T22:58:57.724113Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"import open3d as o3d\nfrom pydicom import dcmread\nimport torch.nn.functional as F\ndef dicom_to_pcd(dir_path,series_type_dict=None,resize_slice=True,resize_method=\"nearest\",img_size=(128,128),downsampling_factor=1\n                ,stack_slices_thickness=True,series_dsc=None):\n    pcd_overall = o3d.geometry.PointCloud()\n    for path in glob.glob(os.path.join(dir_path,\"**/*.dcm\"),recursive=True):\n        dicom_slices = dcmread(path)\n        series_id = os.path.basename(os.path.dirname(path))\n        study_id = os.path.basename(os.path.dirname(os.path.dirname(path)))\n        if series_type_dict is None or int(series_id) not in series_type_dict:\n            series_dsc = dicom_slices.SeriesDescription\n        else:\n            series_dsc = series_type_dict[int(series_dsc)]\n            series_dsc = series_type_dict.split(\" \")[-1]\n        \n        x_orig , y_orig = dicom_slices.pixel_array.shape\n        if resize_slice:\n            if resize_method == \"nearest\":\n                img = np.expand_dims(cv2.resize(dicom_slices.pixel_array,img_size,interpolation=cv2.INTER_AREA),-1)\n            elif resize_method == \"maxpool\":\n                img_tensor = torch.tensor(dicom_slices.pixel_array).float()\n                img = F.adaptive_max_pool2d(img_tensor.unsqueeze(0),img_size).numpy()\n            else:\n                print(\"invalid resize method\")\n        else:\n            img = np.expand_dims(np.array(dicom_slices.pixel_array),-1)\n        x,y,z = np.where(img)\n        downsampling_factor_iter = max(downsampling_factor,int(math.ceil(len(x)/6e6)))\n        index_voxel = np.vstack((x,y,z))[:,::downsampling_factor_iter]\n        grid_index_array = index_voxel.T\n        pcd = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(grid_index_array.astype(np.float64)))\n        vals = np.expand_dims(img[x,y,z][::downsampling_factor_iter],-1)\n        #vals = vals/np.max(vals)\n        if series_dsc == \"T1\":\n            vals = np.pad(vals,((0,0),(0,2)))\n        elif series_dsc == \"T2\":\n            vals = np.pad(vals,((0,0),(1,1)))\n        elif series_dsc == \"T2/STIR\":\n            vals = np.pad(vals,((0,0),(2,0)))   \n        else:\n            vals = np.pad(vals, ((0, 0), (0, 2)), constant_values=-1)\n        \n        vals = vals.astype(np.float64) / 255.0\n        \n        \n        if vals.shape[1] != 3:\n            vals = vals.reshape(-1, 3)\n        pcd.colors = o3d.utility.Vector3dVector(vals.astype(np.float64))\n        if resize_slice:\n            transform_matrix_F = np.matrix([[0,y_orig/img_size[1],0,0],\n                                         [x_orig/img_size[0],0,0,0],\n                                         [0,0,1,0],\n                                         [0,0,0,1]])\n        else:\n            transform_matrix_F = np.matrix([0,1,0,0],   #permutate rows and coloumsn\n                                        [1,0,0,0],\n                                        [0,0,1,0],\n                                        [0,0,0,1])\n        dx , dy = dicom_slices.PixelSpacing\n        dz = dicom_slices.SliceThickness\n        \n        X = np.array(list(dicom_slices.ImageOrientationPatient[:3])+[0]) * dx\n        Y = np.array(list(dicom_slices.ImageOrientationPatient[3:])+[0]) * dy\n        S = np.array(list(dicom_slices.ImagePositionPatient)+[1])\n        transform_matrxi = np.array([X,Y,np.zeros(len(X)),S]).T\n        transform_matrix = transform_matrxi @ transform_matrix_F\n        if stack_slices_thickness:\n            for z in range(int(dz)):\n                pos = list(dicom_slices.ImagePositionPatient)\n                if series_dsc ==\"T2\":\n                    pos[-1] += z\n                else:\n                    pos[0] += z\n                S = np.array(pos +[1])\n                transform_matrxi = np.array([X,Y,np.zeros(len(X)),S]).T\n                transform_matrix = transform_matrxi @ transform_matrix_F\n                pcd_overall += copy.deepcopy(pcd).transform(transform_matrix)\n        else:\n            pcd_overall += copy.deepcopy(pcd).transform(transform_matrix)\n    return pcd_overall","metadata":{"execution":{"iopub.status.busy":"2024-11-03T22:58:57.726156Z","iopub.execute_input":"2024-11-03T22:58:57.727083Z","iopub.status.idle":"2024-11-03T22:59:03.703736Z","shell.execute_reply.started":"2024-11-03T22:58:57.727037Z","shell.execute_reply":"2024-11-03T22:59:03.702925Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"Jupyter environment detected. Enabling Open3D WebVisualizer.\n[Open3D INFO] WebRTC GUI backend enabled.\n[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"converting to 3d image","metadata":{}},{"cell_type":"code","source":"import os\nos.environ['CUDA_LAUNCH_BLOCKING'] = '1'","metadata":{"execution":{"iopub.status.busy":"2024-11-03T22:59:03.706178Z","iopub.execute_input":"2024-11-03T22:59:03.706635Z","iopub.status.idle":"2024-11-03T22:59:03.711043Z","shell.execute_reply.started":"2024-11-03T22:59:03.706600Z","shell.execute_reply":"2024-11-03T22:59:03.710028Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"def create_dataset_and_loaders_kfolds(df, base_path, transform_train=None, transform_val=None, batch_size=16, split_k=5):\n    df = df.dropna()\n    np.random.seed()\n    study_ids = df[\"study_id\"].unique()\n    np.random.shuffle(study_ids)\n    folds = np.array_split(study_ids, split_k) \n    loaders = []\n    \n    for fold in folds:\n        val_df = df[df[\"study_id\"].isin(fold)]\n        train_df = df[~df[\"study_id\"].isin(fold)]\n        \n        train_df.reset_index(drop=True, inplace=True)\n        val_df.reset_index(drop=True, inplace=True)\n        \n        # Calculate 20% of the dataset sizes\n        train_size = int(len(train_df) * 0.2)\n        val_size = int(len(val_df) * 0.2)\n        \n        # Limit the datasets to 20%\n        train_df = train_df.iloc[:train_size]\n        val_df = val_df.iloc[:val_size]\n        \n        train_dataset = studyleveldataset(train_df, base_path, transform_3d=transform_train)\n        val_dataset = studyleveldataset(val_df, base_path, transform_3d=transform_val)\n        \n        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=False)\n        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=False)\n        \n        loaders.append((train_loader, val_loader, train_dataset, val_dataset))\n    \n    return loaders\n","metadata":{"execution":{"iopub.status.busy":"2024-11-03T22:59:03.712623Z","iopub.execute_input":"2024-11-03T22:59:03.713022Z","iopub.status.idle":"2024-11-03T22:59:07.909128Z","shell.execute_reply.started":"2024-11-03T22:59:03.712958Z","shell.execute_reply":"2024-11-03T22:59:07.908100Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"def read_study_voxel_grid(dir_path,study_id,img_size=(128,128),chaching=True,chace_base_path=\"/kaggle/working/3d_chache\",downsampling_factor=1,\n                          series_type_dict=None):\n    if chaching:\n        os.makedirs(os.path.join(chace_base_path,str(study_id)),exist_ok=True)\n        cahe_path = os.path.join(chace_base_path,str(study_id),f\"cached_grid_v2_{img_size[0]}.npy.gz\")\n        f = None\n        if os.path.exists(cahe_path):\n            try:\n                f = pgzip.PgzipFile(cahe_path,\"r\")\n                ret = np.load(f,allow_pickle=True)\n                f.close()\n                return ret\n            except Exception as e:\n                print(dir_path,\"\\n\",e)\n                if f:\n                    f.close()\n                os.remove(cahe_path)\n        \n    pcd_overall = dicom_to_pcd(dir_path,series_type_dict=series_type_dict,downsampling_factor=downsampling_factor,img_size=img_size)\n    if pcd_overall is None:\n        raise ValueError(f\"Failed to create point cloud for study ID {study_id}. Check if DICOM files are correctly processed.\")\n\n    box = pcd_overall.get_axis_aligned_bounding_box()\n    max_b = np.array(box.get_max_bound())\n    min_b = np.array(box.get_min_bound())\n    pts = (np.array(pcd_overall.points)-min_b) * (img_size[0]-1,img_size[0]-1,img_size[0]-1) / (max_b - min_b)\n    coords = np.round(pts).astype(np.int32)\n    vals = np.array(pcd_overall.colors,dtype=np.float16)\n    grid = np.zeros((3,img_size[0],img_size[0],img_size[0]),dtype=np.float16)\n    indicies = coords[:,0] , coords[:,1] , coords[:,2]\n    \n    np.maximum.at(grid[0],indicies,vals[:,0])\n    np.maximum.at(grid[1],indicies,vals[:,1])\n    np.maximum.at(grid[2],indicies,vals[:,2])\n    \n    if chaching:\n        f = pgzip.PgzipFile(cahe_path,\"w\")\n        np.save(f,grid)\n        f.close()\n    return grid","metadata":{"execution":{"iopub.status.busy":"2024-11-03T22:59:07.910344Z","iopub.execute_input":"2024-11-03T22:59:07.910784Z","iopub.status.idle":"2024-11-03T22:59:07.924352Z","shell.execute_reply.started":"2024-11-03T22:59:07.910740Z","shell.execute_reply":"2024-11-03T22:59:07.923456Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"LABEL_MAP = {'normal_mild': 0, 'moderate': 1, 'severe': 2}","metadata":{"execution":{"iopub.status.busy":"2024-11-03T22:59:07.925578Z","iopub.execute_input":"2024-11-03T22:59:07.925947Z","iopub.status.idle":"2024-11-03T22:59:07.941164Z","shell.execute_reply.started":"2024-11-03T22:59:07.925904Z","shell.execute_reply":"2024-11-03T22:59:07.940310Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset ,DataLoader","metadata":{"execution":{"iopub.status.busy":"2024-11-03T22:59:07.942256Z","iopub.execute_input":"2024-11-03T22:59:07.942586Z","iopub.status.idle":"2024-11-03T22:59:07.950351Z","shell.execute_reply.started":"2024-11-03T22:59:07.942555Z","shell.execute_reply":"2024-11-03T22:59:07.949432Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"min(LABEL_MAP.values())","metadata":{"execution":{"iopub.status.busy":"2024-11-03T22:59:07.951513Z","iopub.execute_input":"2024-11-03T22:59:07.952126Z","iopub.status.idle":"2024-11-03T22:59:07.960621Z","shell.execute_reply.started":"2024-11-03T22:59:07.952082Z","shell.execute_reply":"2024-11-03T22:59:07.959733Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"max(LABEL_MAP.values())","metadata":{"execution":{"iopub.status.busy":"2024-11-03T22:59:07.964373Z","iopub.execute_input":"2024-11-03T22:59:07.964664Z","iopub.status.idle":"2024-11-03T22:59:07.970298Z","shell.execute_reply.started":"2024-11-03T22:59:07.964634Z","shell.execute_reply":"2024-11-03T22:59:07.969465Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"2"},"metadata":{}}]},{"cell_type":"code","source":"from torch.utils.data import Dataset\nimport numpy as np\nimport pandas as pd\nimport torch\nimport os\n\nclass studyleveldataset(Dataset):\n    def __init__(self, dataframe: pd.DataFrame, base_path, transform_3d, vol_size=(128, 128, 128), is_mirror=False):\n        self.base_path = base_path\n        self.is_mirror = is_mirror\n        self.dataframe = dataframe[[\"study_id\", \"series_id\", \"series_description\", \"condition\", \"severity\", \"level\"]].drop_duplicates()\n        self.subjects = self.dataframe[[\"study_id\"]].drop_duplicates().reset_index()\n        self.series = self.dataframe[[\"study_id\", \"series_id\"]].drop_duplicates().groupby(\"study_id\")[\"series_id\"].apply(list).to_dict()\n        self.series_descs = {e[0]: e[1] for e in self.dataframe[[\"study_id\", \"series_description\"]].drop_duplicates().values}\n        self.transforms_3d = transform_3d\n        self.levels = sorted(self.dataframe[\"level\"].unique())\n        self.labels = self._get_labels()\n        self.vol_size = vol_size\n\n    def __len__(self):\n        return len(self.subjects) * (2 if self.is_mirror else 1)\n\n    def __getitem__(self, index):\n        is_mirror = index >= len(self.subjects)\n        curr = self.subjects.iloc[index % len(self.subjects)]\n        label_array = np.array(self.labels[curr[\"study_id\"]])\n        study_path = os.path.join(self.base_path, str(curr[\"study_id\"]))\n        study_images = read_study_voxel_grid(study_path, curr[\"study_id\"], series_type_dict=self.series_descs)\n        \n        # Padding the label array\n        max_length = 25  \n        label_array = np.pad(label_array, (3, max(0, max_length - len(label_array))), 'constant', constant_values=3)  # Padding with '3'\n\n        # Mirror operation on the label array\n        if is_mirror:\n            half_length = len(label_array) // 2\n            temp = label_array[:half_length].copy()\n            label_array[:half_length] = label_array[half_length:].copy()\n            label_array[half_length:] = temp\n\n        # Apply majority voting to get a single label\n        label = self.apply_majority_voting(label_array)\n        \n        # Apply 3D transformations if provided\n        if self.transforms_3d is not None:\n            study_images = torch.FloatTensor(study_images)\n            if is_mirror:\n                study_images = torch.flip(study_images, [1])\n            study_images = self.transforms_3d(study_images)\n            return study_images.to(torch.half), torch.tensor(label, dtype=torch.long)\n        \n        return torch.FloatTensor(study_images.copy()), torch.tensor(label, dtype=torch.long)\n\n    def _get_labels(self):\n        labels = dict()\n        for study_id, group in self.dataframe.groupby(\"study_id\"):\n            group = group[[\"condition\", \"level\", \"severity\"]].drop_duplicates().sort_values([\"condition\", \"level\"])\n            label_indices = []\n            for _, row in group.iterrows():\n                if row[\"severity\"] in LABEL_MAP:\n                    label_indices.append(LABEL_MAP[row[\"severity\"]])\n                else:\n                    label_indices.append(3)  # Default to padding value if severity is missing\n            labels[study_id] = label_indices\n        return labels\n\n    def apply_majority_voting(self, label_array):\n        valid_labels = label_array[label_array != 3]  # Exclude padding\n        if len(valid_labels) == 0:\n            print(\"d\")\n            # If all labels are padding, return a default value (e.g., the most frequent class 0)\n            return 0\n        \n        return np.bincount(valid_labels).argmax()  # Majority voting on valid labels only\n","metadata":{"execution":{"iopub.status.busy":"2024-11-03T22:59:07.971582Z","iopub.execute_input":"2024-11-03T22:59:07.971919Z","iopub.status.idle":"2024-11-03T22:59:07.991403Z","shell.execute_reply.started":"2024-11-03T22:59:07.971878Z","shell.execute_reply":"2024-11-03T22:59:07.990639Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"pip install torchio","metadata":{"execution":{"iopub.status.busy":"2024-11-03T22:59:07.992428Z","iopub.execute_input":"2024-11-03T22:59:07.992747Z","iopub.status.idle":"2024-11-03T22:59:20.154844Z","shell.execute_reply.started":"2024-11-03T22:59:07.992706Z","shell.execute_reply":"2024-11-03T22:59:20.153681Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Collecting torchio\n  Downloading torchio-0.20.1-py3-none-any.whl.metadata (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: deprecated in /opt/conda/lib/python3.10/site-packages (from torchio) (1.2.14)\nRequirement already satisfied: humanize in /opt/conda/lib/python3.10/site-packages (from torchio) (4.9.0)\nRequirement already satisfied: nibabel in /opt/conda/lib/python3.10/site-packages (from torchio) (5.2.1)\nRequirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.10/site-packages (from torchio) (1.26.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from torchio) (1.14.1)\nRequirement already satisfied: simpleitk!=2.0.*,!=2.1.1.1 in /opt/conda/lib/python3.10/site-packages (from torchio) (2.4.0)\nRequirement already satisfied: torch>=1.1 in /opt/conda/lib/python3.10/site-packages (from torchio) (2.4.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torchio) (4.66.4)\nRequirement already satisfied: typer in /opt/conda/lib/python3.10/site-packages (from torchio) (0.12.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.1->torchio) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.1->torchio) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.1->torchio) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.1->torchio) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.1->torchio) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.1->torchio) (2024.6.1)\nRequirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from deprecated->torchio) (1.16.0)\nRequirement already satisfied: packaging>=17 in /opt/conda/lib/python3.10/site-packages (from nibabel->torchio) (21.3)\nRequirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from typer->torchio) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer->torchio) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer->torchio) (13.7.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=17->nibabel->torchio) (3.1.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer->torchio) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer->torchio) (2.18.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.1->torchio) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.1->torchio) (1.3.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer->torchio) (0.1.2)\nDownloading torchio-0.20.1-py3-none-any.whl (175 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.5/175.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: torchio\nSuccessfully installed torchio-0.20.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport torchio as tio\nimport os\n\ndata_path = \"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification\"\n\ntransform = tio.Compose([tio.RescaleIntensity(out_min_max=(0,1))])\nfolds = create_dataset_and_loaders_kfolds(train_data,base_path=os.path.join(data_path,\"train_images\"))","metadata":{"execution":{"iopub.status.busy":"2024-11-03T22:59:20.156659Z","iopub.execute_input":"2024-11-03T22:59:20.157108Z","iopub.status.idle":"2024-11-03T22:59:27.587622Z","shell.execute_reply.started":"2024-11-03T22:59:20.157056Z","shell.execute_reply":"2024-11-03T22:59:27.586598Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"pip install pgzip","metadata":{"execution":{"iopub.status.busy":"2024-11-03T22:59:27.589033Z","iopub.execute_input":"2024-11-03T22:59:27.589356Z","iopub.status.idle":"2024-11-03T22:59:39.532184Z","shell.execute_reply.started":"2024-11-03T22:59:27.589317Z","shell.execute_reply":"2024-11-03T22:59:39.530956Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"Collecting pgzip\n  Downloading pgzip-0.3.5-py3-none-any.whl.metadata (4.6 kB)\nDownloading pgzip-0.3.5-py3-none-any.whl (13 kB)\nInstalling collected packages: pgzip\nSuccessfully installed pgzip-0.3.5\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import glob\nimport cv2\nimport math , copy ,pgzip , torch","metadata":{"execution":{"iopub.status.busy":"2024-11-03T22:59:39.534033Z","iopub.execute_input":"2024-11-03T22:59:39.534838Z","iopub.status.idle":"2024-11-03T22:59:39.720462Z","shell.execute_reply.started":"2024-11-03T22:59:39.534785Z","shell.execute_reply":"2024-11-03T22:59:39.719491Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"train_loader,val_loader,train_dataset,val_dataset=folds[0]","metadata":{"execution":{"iopub.status.busy":"2024-11-03T22:59:39.721903Z","iopub.execute_input":"2024-11-03T22:59:39.722557Z","iopub.status.idle":"2024-11-03T22:59:39.727133Z","shell.execute_reply.started":"2024-11-03T22:59:39.722512Z","shell.execute_reply":"2024-11-03T22:59:39.726280Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n","metadata":{"execution":{"iopub.status.busy":"2024-11-03T22:59:39.729590Z","iopub.execute_input":"2024-11-03T22:59:39.730407Z","iopub.status.idle":"2024-11-03T22:59:39.741488Z","shell.execute_reply.started":"2024-11-03T22:59:39.730372Z","shell.execute_reply":"2024-11-03T22:59:39.740637Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"study_images , labels = next(iter(train_loader))\nprint(study_images.shape)\nprint(labels.shape)\nprint(labels)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T22:59:39.742686Z","iopub.execute_input":"2024-11-03T22:59:39.742986Z","iopub.status.idle":"2024-11-03T23:01:12.239676Z","shell.execute_reply.started":"2024-11-03T22:59:39.742937Z","shell.execute_reply":"2024-11-03T23:01:12.237155Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"torch.Size([16, 3, 128, 128, 128])\ntorch.Size([16])\ntensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0])\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.optim as optim","metadata":{"execution":{"iopub.status.busy":"2024-11-03T23:28:28.896838Z","iopub.execute_input":"2024-11-03T23:28:28.897237Z","iopub.status.idle":"2024-11-03T23:28:28.901757Z","shell.execute_reply.started":"2024-11-03T23:28:28.897200Z","shell.execute_reply":"2024-11-03T23:28:28.900779Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass PatchEmbed3D(nn.Module):\n    def __init__(self, img_size, patch_size=16, in_chans=3, embed_dim=768):\n        super().__init__()\n        self.img_size = img_size\n        self.patch_size = patch_size\n        self.num_patches = (img_size // patch_size) ** 3\n        self.proj = nn.Conv3d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n\n    def forward(self, x):\n        x = self.proj(x)\n        x = x.flatten(2)  # (batch_size, embed_dim, num_patches)\n        x = x.transpose(1, 2)  # (batch_size, num_patches, embed_dim)\n        return x\n\nclass Attention3D(nn.Module):\n    def __init__(self, dim, num_heads=8, qkv_bias=False, attn_drop=0., proj_drop=0.):\n        super().__init__()\n        self.num_heads = num_heads\n        head_dim = dim // num_heads\n        self.scale = head_dim ** -0.5\n\n        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n        self.attn_drop = nn.Dropout(attn_drop)\n        self.proj = nn.Linear(dim, dim)\n        self.proj_dropout = nn.Dropout(proj_drop)\n\n    def forward(self, x):\n        B, N, C = x.shape\n        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n        q, k, v = qkv[0], qkv[1], qkv[2]\n\n        attn = (q @ k.transpose(-2, -1)) * self.scale\n        attn = attn.softmax(dim=-1)\n        attn = self.attn_drop(attn)\n\n        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n        x = self.proj(x)\n        x = self.proj_dropout(x)\n\n        return x\n\nclass TransformerBlock3D(nn.Module):\n    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, drop=0., attn_drop=0., act_layer=nn.GELU):\n        super().__init__()\n        self.norm1 = nn.LayerNorm(dim)\n        self.attn = Attention3D(dim, num_heads, qkv_bias, attn_drop, drop)\n        self.norm2 = nn.LayerNorm(dim)\n        mlp_hidden_dim = int(dim * mlp_ratio)\n        self.mlp = nn.Sequential(\n            nn.Linear(dim, mlp_hidden_dim),\n            act_layer(),\n            nn.Dropout(drop),\n            nn.Linear(mlp_hidden_dim, dim),\n            nn.Dropout(drop)\n        )\n\n    def forward(self, x):\n        x = x + self.attn(self.norm1(x))\n        x = x + self.mlp(self.norm2(x))\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-11-03T23:28:29.166403Z","iopub.execute_input":"2024-11-03T23:28:29.166790Z","iopub.status.idle":"2024-11-03T23:28:29.183323Z","shell.execute_reply.started":"2024-11-03T23:28:29.166751Z","shell.execute_reply":"2024-11-03T23:28:29.182339Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"class visiontransformer3D(nn.Module):\n    def __init__(self,img_size=128,patch_size=16,in_channels=3,num_class=3,embed_dim=768,depth=12,num_heads=3,mlp_ratio=4.,qkv_bias=0,drop_rate=0,attn_drop_rate=0.):\n        super().__init__()\n        self.patch_embed = PatchEmbed3D(img_size=img_size)\n        num_patches = self.patch_embed.num_patches\n        self.cls_token = nn.Parameter(torch.zeros(1,1,embed_dim))\n        self.pos_token = nn.Parameter(torch.zeros(1,num_patches+1,embed_dim))\n        self.pos_drop = nn.Dropout(p=drop_rate)\n        self.blocks = nn.ModuleList([\n            TransformerBlock3D(dim=embed_dim, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, drop=drop_rate, attn_drop=attn_drop_rate)\n            for _ in range(depth)\n        ])\n\n        self.norm = nn.LayerNorm(embed_dim)\n        self.head = nn.Linear(embed_dim, 3 )  \n\n        nn.init.trunc_normal_(self.pos_token, std=.02)\n        nn.init.trunc_normal_(self.cls_token, std=.02)\n        self.apply(self._init_weights)\n    def _init_weights(self, m):\n        if isinstance(m, nn.Linear):\n            nn.init.trunc_normal_(m.weight, std=.02)\n            if m.bias is not None:\n                nn.init.constant_(m.bias, 0)\n        elif isinstance(m, nn.LayerNorm):\n            nn.init.constant_(m.bias, 0)\n            nn.init.constant_(m.weight, 1.0)\n    def forward(self,x):\n        B = x.shape[0]\n        x = self.patch_embed(x)\n        cls_token = self.cls_token.expand(B,-1,-1)\n        x = torch.cat((cls_token,x),dim=1)\n        \n        x = x + self.pos_token\n        x = self.pos_drop(x)\n        \n        for block in self.blocks:\n            x = block(x)\n        x = self.norm(x)\n        x = x[:,0]\n        x = self.head(x)\n        x=F.softmax(x, dim=-1)\n        x = x.view(B,3)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-11-03T23:28:29.597946Z","iopub.execute_input":"2024-11-03T23:28:29.598877Z","iopub.status.idle":"2024-11-03T23:28:29.612604Z","shell.execute_reply.started":"2024-11-03T23:28:29.598833Z","shell.execute_reply":"2024-11-03T23:28:29.611551Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"model = visiontransformer3D()\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-03T23:28:30.160104Z","iopub.execute_input":"2024-11-03T23:28:30.160594Z","iopub.status.idle":"2024-11-03T23:28:31.887151Z","shell.execute_reply.started":"2024-11-03T23:28:30.160549Z","shell.execute_reply":"2024-11-03T23:28:31.886192Z"},"trusted":true},"execution_count":76,"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"visiontransformer3D(\n  (patch_embed): PatchEmbed3D(\n    (proj): Conv3d(3, 768, kernel_size=(16, 16, 16), stride=(16, 16, 16))\n  )\n  (pos_drop): Dropout(p=0, inplace=False)\n  (blocks): ModuleList(\n    (0-11): 12 x TransformerBlock3D(\n      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (attn): Attention3D(\n        (qkv): Linear(in_features=768, out_features=2304, bias=False)\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_dropout): Dropout(p=0, inplace=False)\n      )\n      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (mlp): Sequential(\n        (0): Linear(in_features=768, out_features=3072, bias=True)\n        (1): GELU(approximate='none')\n        (2): Dropout(p=0, inplace=False)\n        (3): Linear(in_features=3072, out_features=768, bias=True)\n        (4): Dropout(p=0, inplace=False)\n      )\n    )\n  )\n  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  (head): Linear(in_features=768, out_features=3, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nimport torch.optim as optim\nimport numpy as np\nfrom tqdm import tqdm\n\ndef train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10, device='cpu'):\n    for epoch in range(num_epochs):\n        model.train()\n        epoch_loss = 0.0\n        epoch_correct = 0\n        epoch_total = 0\n        \n        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} [Train]\", unit=\"batch\")\n        \n        for batch_idx, (images, labels) in enumerate(train_pbar):\n            images, labels = images.to(device), labels.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            \n            loss.backward()\n            optimizer.step()\n            \n            # Update batch statistics\n            _, predicted = torch.max(outputs.data, 1)\n            batch_correct = (predicted == labels).sum().item()\n            batch_total = labels.size(0)\n            \n            # Update epoch statistics\n            epoch_loss += loss.item()\n            epoch_correct += batch_correct\n            epoch_total += batch_total\n            \n            # Update progress bar with current batch statistics\n            batch_acc = batch_correct / batch_total\n            train_pbar.set_postfix({\n                'loss': f'{loss.item():.4f}',\n                'acc': f'{batch_acc:.4f}'\n            })\n        \n        # Calculate epoch statistics\n        epoch_avg_loss = epoch_loss / len(train_loader)\n        epoch_accuracy = epoch_correct / epoch_total\n        \n        print(f\"\\nEpoch {epoch + 1} Summary:\")\n        print(f\"Training Loss: {epoch_avg_loss:.4f}, Training Accuracy: {epoch_accuracy:.4f}\")\n        \n        # Validation phase\n        validate_model(model, val_loader, criterion, device)\n        print()  # Add blank line between epochs\n\ndef validate_model(model, val_loader, criterion, device='cpu'):\n    model.eval()\n    val_loss = 0.0\n    val_correct = 0\n    val_total = 0\n    \n    # Add tqdm for validation\n    val_pbar = tqdm(val_loader, desc=\"Validation\", unit=\"batch\")\n    \n    with torch.no_grad():\n        for images, labels in val_pbar:\n            images, labels = images.to(device), labels.to(device)\n            \n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            \n            # Update validation statistics\n            val_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            batch_correct = (predicted == labels).sum().item()\n            batch_total = labels.size(0)\n            \n            val_correct += batch_correct\n            val_total += batch_total\n            \n            # Update validation progress bar\n            batch_acc = batch_correct / batch_total\n            val_pbar.set_postfix({\n                'loss': f'{loss.item():.4f}',\n                'acc': f'{batch_acc:.4f}'\n            })\n    \n    # Calculate final validation metrics\n    val_avg_loss = val_loss / len(val_loader)\n    val_accuracy = val_correct / val_total\n    \n    print(f\"\\nValidation Summary:\")\n    print(f\"Validation Loss: {val_avg_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n\nif __name__ == \"__main__\":\n    # Assuming you have your dataset and dataloaders ready\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = visiontransformer3D().to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    for fold, (train_loader, val_loader, train_dataset, val_dataset) in enumerate(folds, 1):\n        print(f\"\\nStarting training for fold {fold}\")\n        print(\"=\" * 50)\n        train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10, device=device)\n        print(\"=\" * 50)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T23:35:06.362169Z","iopub.execute_input":"2024-11-03T23:35:06.363127Z","iopub.status.idle":"2024-11-04T00:00:33.030831Z","shell.execute_reply.started":"2024-11-03T23:35:06.363077Z","shell.execute_reply":"2024-11-04T00:00:33.029642Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"\nStarting training for fold 1\n==================================================\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.19s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1 Summary:\nTraining Loss: 0.6148, Training Accuracy: 0.9525\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.12s/batch, loss=0.7514, acc=0.8000]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.5914, Validation Accuracy: 0.9620\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.17s/batch, loss=0.6348, acc=0.9167]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2 Summary:\nTraining Loss: 0.5931, Training Accuracy: 0.9589\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.12s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.5889, Validation Accuracy: 0.9620\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.16s/batch, loss=0.6348, acc=0.9167]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3 Summary:\nTraining Loss: 0.5931, Training Accuracy: 0.9589\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.06s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.5889, Validation Accuracy: 0.9620\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/10 [Train]: 100%|██████████| 20/20 [00:22<00:00,  1.14s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4 Summary:\nTraining Loss: 0.5921, Training Accuracy: 0.9589\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.19s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.5889, Validation Accuracy: 0.9620\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.16s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 5 Summary:\nTraining Loss: 0.5921, Training Accuracy: 0.9589\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:06<00:00,  1.23s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.5889, Validation Accuracy: 0.9620\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.18s/batch, loss=0.6348, acc=0.9167]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 6 Summary:\nTraining Loss: 0.5931, Training Accuracy: 0.9589\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.14s/batch, loss=0.6848, acc=0.8667]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.5906, Validation Accuracy: 0.9620\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.17s/batch, loss=0.6348, acc=0.9167]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 7 Summary:\nTraining Loss: 0.5931, Training Accuracy: 0.9589\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.13s/batch, loss=0.6181, acc=0.9333]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.5898, Validation Accuracy: 0.9620\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.18s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 8 Summary:\nTraining Loss: 0.5921, Training Accuracy: 0.9589\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.14s/batch, loss=0.6181, acc=0.9333]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.5898, Validation Accuracy: 0.9620\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.18s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 9 Summary:\nTraining Loss: 0.5921, Training Accuracy: 0.9589\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.13s/batch, loss=0.6848, acc=0.8667]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.5906, Validation Accuracy: 0.9620\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.18s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 10 Summary:\nTraining Loss: 0.5921, Training Accuracy: 0.9589\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.13s/batch, loss=0.6848, acc=0.8667]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.5906, Validation Accuracy: 0.9620\n\n==================================================\n\nStarting training for fold 2\n==================================================\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.17s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1 Summary:\nTraining Loss: 0.5889, Training Accuracy: 0.9620\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:35<00:00,  7.16s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.6264, Validation Accuracy: 0.9241\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.16s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2 Summary:\nTraining Loss: 0.5889, Training Accuracy: 0.9620\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.13s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.6264, Validation Accuracy: 0.9241\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.17s/batch, loss=0.6348, acc=0.9167]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3 Summary:\nTraining Loss: 0.5900, Training Accuracy: 0.9620\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.11s/batch, loss=0.7514, acc=0.8000]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.6289, Validation Accuracy: 0.9241\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.17s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4 Summary:\nTraining Loss: 0.5889, Training Accuracy: 0.9620\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.12s/batch, loss=0.6181, acc=0.9333]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.6273, Validation Accuracy: 0.9241\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.16s/batch, loss=0.7181, acc=0.8333]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 5 Summary:\nTraining Loss: 0.5910, Training Accuracy: 0.9620\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.15s/batch, loss=0.6181, acc=0.9333]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.6273, Validation Accuracy: 0.9241\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.16s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 6 Summary:\nTraining Loss: 0.5889, Training Accuracy: 0.9620\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.14s/batch, loss=0.6181, acc=0.9333]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.6273, Validation Accuracy: 0.9241\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/10 [Train]: 100%|██████████| 20/20 [00:22<00:00,  1.15s/batch, loss=0.6348, acc=0.9167]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 7 Summary:\nTraining Loss: 0.5900, Training Accuracy: 0.9620\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.12s/batch, loss=0.6181, acc=0.9333]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.6273, Validation Accuracy: 0.9241\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.18s/batch, loss=0.6348, acc=0.9167]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 8 Summary:\nTraining Loss: 0.5900, Training Accuracy: 0.9620\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.12s/batch, loss=0.6181, acc=0.9333]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.6273, Validation Accuracy: 0.9241\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.16s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 9 Summary:\nTraining Loss: 0.5889, Training Accuracy: 0.9620\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.12s/batch, loss=0.6181, acc=0.9333]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.6273, Validation Accuracy: 0.9241\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.17s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 10 Summary:\nTraining Loss: 0.5889, Training Accuracy: 0.9620\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.12s/batch, loss=0.6181, acc=0.9333]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.6273, Validation Accuracy: 0.9241\n\n==================================================\n\nStarting training for fold 3\n==================================================\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10 [Train]: 100%|██████████| 20/20 [00:38<00:00,  1.92s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1 Summary:\nTraining Loss: 0.5983, Training Accuracy: 0.9524\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.16s/batch, loss=0.6139, acc=0.9375]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.6014, Validation Accuracy: 0.9500\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.16s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2 Summary:\nTraining Loss: 0.5983, Training Accuracy: 0.9524\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.13s/batch, loss=0.6139, acc=0.9375]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.6014, Validation Accuracy: 0.9500\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.17s/batch, loss=0.6424, acc=0.9091]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3 Summary:\nTraining Loss: 0.5997, Training Accuracy: 0.9524\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.12s/batch, loss=0.6139, acc=0.9375]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.6014, Validation Accuracy: 0.9500\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.16s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4 Summary:\nTraining Loss: 0.5983, Training Accuracy: 0.9524\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.13s/batch, loss=0.6139, acc=0.9375]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.6014, Validation Accuracy: 0.9500\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.17s/batch, loss=0.6424, acc=0.9091]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 5 Summary:\nTraining Loss: 0.5997, Training Accuracy: 0.9524\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.12s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.6014, Validation Accuracy: 0.9500\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.17s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 6 Summary:\nTraining Loss: 0.5983, Training Accuracy: 0.9524\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.13s/batch, loss=0.6139, acc=0.9375]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.6014, Validation Accuracy: 0.9500\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.16s/batch, loss=0.6424, acc=0.9091]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 7 Summary:\nTraining Loss: 0.5997, Training Accuracy: 0.9524\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.13s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.6014, Validation Accuracy: 0.9500\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.16s/batch, loss=0.6424, acc=0.9091]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 8 Summary:\nTraining Loss: 0.5997, Training Accuracy: 0.9524\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.13s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.6014, Validation Accuracy: 0.9500\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.17s/batch, loss=0.6424, acc=0.9091]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 9 Summary:\nTraining Loss: 0.5997, Training Accuracy: 0.9524\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.13s/batch, loss=0.6139, acc=0.9375]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.6014, Validation Accuracy: 0.9500\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.17s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 10 Summary:\nTraining Loss: 0.5983, Training Accuracy: 0.9524\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.13s/batch, loss=0.6139, acc=0.9375]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.6014, Validation Accuracy: 0.9500\n\n==================================================\n\nStarting training for fold 4\n==================================================\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10 [Train]: 100%|██████████| 20/20 [00:41<00:00,  2.08s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1 Summary:\nTraining Loss: 0.5983, Training Accuracy: 0.9524\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.12s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.5889, Validation Accuracy: 0.9620\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.17s/batch, loss=0.6424, acc=0.9091]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2 Summary:\nTraining Loss: 0.5997, Training Accuracy: 0.9524\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.12s/batch, loss=0.6181, acc=0.9333]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.5898, Validation Accuracy: 0.9620\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.17s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3 Summary:\nTraining Loss: 0.5983, Training Accuracy: 0.9524\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.12s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.5889, Validation Accuracy: 0.9620\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.17s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4 Summary:\nTraining Loss: 0.5983, Training Accuracy: 0.9524\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.13s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.5889, Validation Accuracy: 0.9620\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.17s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 5 Summary:\nTraining Loss: 0.5983, Training Accuracy: 0.9524\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.12s/batch, loss=0.6181, acc=0.9333]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.5898, Validation Accuracy: 0.9620\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.16s/batch, loss=0.6424, acc=0.9091]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 6 Summary:\nTraining Loss: 0.5997, Training Accuracy: 0.9524\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.12s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.5889, Validation Accuracy: 0.9620\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.16s/batch, loss=0.6424, acc=0.9091]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 7 Summary:\nTraining Loss: 0.5997, Training Accuracy: 0.9524\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.18s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.5889, Validation Accuracy: 0.9620\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.17s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 8 Summary:\nTraining Loss: 0.5983, Training Accuracy: 0.9524\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.13s/batch, loss=0.6181, acc=0.9333]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.5898, Validation Accuracy: 0.9620\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.17s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 9 Summary:\nTraining Loss: 0.5983, Training Accuracy: 0.9524\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.11s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.5889, Validation Accuracy: 0.9620\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.17s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 10 Summary:\nTraining Loss: 0.5983, Training Accuracy: 0.9524\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.10s/batch, loss=0.6181, acc=0.9333]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.5898, Validation Accuracy: 0.9620\n\n==================================================\n\nStarting training for fold 5\n==================================================\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.17s/batch, loss=0.6348, acc=0.9167]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1 Summary:\nTraining Loss: 0.5962, Training Accuracy: 0.9557\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:11<00:00,  2.32s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.5764, Validation Accuracy: 0.9747\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.16s/batch, loss=0.6348, acc=0.9167]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2 Summary:\nTraining Loss: 0.5962, Training Accuracy: 0.9557\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.11s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.5764, Validation Accuracy: 0.9747\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.17s/batch, loss=0.6348, acc=0.9167]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3 Summary:\nTraining Loss: 0.5962, Training Accuracy: 0.9557\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.11s/batch, loss=0.6181, acc=0.9333]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.5773, Validation Accuracy: 0.9747\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.17s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4 Summary:\nTraining Loss: 0.5952, Training Accuracy: 0.9557\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.11s/batch, loss=0.6848, acc=0.8667]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.5781, Validation Accuracy: 0.9747\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.17s/batch, loss=0.6348, acc=0.9167]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 5 Summary:\nTraining Loss: 0.5962, Training Accuracy: 0.9557\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.10s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.5764, Validation Accuracy: 0.9747\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.17s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 6 Summary:\nTraining Loss: 0.5952, Training Accuracy: 0.9557\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.10s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.5764, Validation Accuracy: 0.9747\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.17s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 7 Summary:\nTraining Loss: 0.5952, Training Accuracy: 0.9557\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.11s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.5764, Validation Accuracy: 0.9747\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.17s/batch, loss=0.7181, acc=0.8333]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 8 Summary:\nTraining Loss: 0.5973, Training Accuracy: 0.9557\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.11s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.5764, Validation Accuracy: 0.9747\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.17s/batch, loss=0.6348, acc=0.9167]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 9 Summary:\nTraining Loss: 0.5962, Training Accuracy: 0.9557\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.11s/batch, loss=0.6848, acc=0.8667]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.5781, Validation Accuracy: 0.9747\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/10 [Train]: 100%|██████████| 20/20 [00:23<00:00,  1.16s/batch, loss=0.5514, acc=1.0000]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 10 Summary:\nTraining Loss: 0.5952, Training Accuracy: 0.9557\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:05<00:00,  1.16s/batch, loss=0.5514, acc=1.0000]","output_type":"stream"},{"name":"stdout","text":"\nValidation Summary:\nValidation Loss: 0.5764, Validation Accuracy: 0.9747\n\n==================================================\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}